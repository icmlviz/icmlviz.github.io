---
layout: default
title: Home
permalink: /home/
order: 1
---


# 2017 Workshop on Visualization for Deep Learning
![Teaser](/assets/deepdream.jpg)

###### Image credit: [Deep Dream Generator], and Google [Inceptionism]
 

## Abstract##

Deep networks have had profound impact across machine learning research and in many application areas. DNNs are complex to design and train. They are non-linear systems that almost always have many local optima and are often sensitive to training parameter settings and initial state. Systematic optimization of structure and hyperparameters is possible e.g. with Bayesian optimization, but hampered by the expense of training each design on realistic datasets. Exploration is still ongoing for best design principles. We argue that visualization can play an essential role in understanding DNNs and in developing new design principles. With rich tools for visual exploration of networks during training and inference, one should be able to form closer ties between theory and practice: validating expected behaviors, and exposing the unexpected which can lead to new insights. 

The workshop has been held ***[last year]***. This year, with the rise of generative modeling and reinforcement learning, more interesting directions like understanding and visualization of generative models, visual explanation for driving policy could be explored as well. 

***[Here]*** is a list of reference papers related to this topics in the past. Let us know if you can recommend more!  

## Important Dates ##

Submission deadline: 9PM PDT, June 10, 2017 (Could be extended)

Acceptance notification:  June 16, 2017

Workshop: ***Aug 10, 2017*** at Sydney, Australia, [ICML 2017]


## Invited speakers ##

To be announced

## Organizers:
	
##### [John Canny] (UC Berkeley, canny@berkeley.edu)

##### [Polo Chau] (Georgia Tech, polo@gatech.edu)

##### [Xiangmin Fan] (Chinese Academy of Sciences, xiangmin@cs.pitt.edu)

##### [Biye Jiang] (UC Berkeley, bjiang@berkeley.edu)

##### [Jun-Yan Zhu] (UC Berkeley, junyanz@berkeley.edu)

## Program Committee ##

##### [Jeff Clune], University of Wyoming

##### [Wojciech Samek], Heinrich Hertz Institute
 
##### [Yingnian Wu], University of California, Los Angeles

##### [Jason Yosinski], Uber AI Labs

##### [Devi Parikh], Georgia Tech


## Sponsor ##
To be announced


## Topics:##
Likely topics for the workshop include, but are not limited to:

•	Directly visualizing the activations and parameters in intuitive aggregates

•	Visualizing weights as features

•	Visualizing gradient aggregates during training

•	Improving interpretability of networks:

•	Localizing "responsbility" in the network for particular outputs

•	Sensitivity/stability of network behavior

•	Visualizing loss function geometry and the trajectory of the gradient descent process

•	Visual representation of the input-output mapping of the network

•	Visualizing alternative structures and their performance

•	Monitoring/debugging the training process, i.e to detect saddle points or local optima, saturation units

•	Visualizing distributed training methods across a cluster

•	Using animation in network visualization

•	Interactive visualizations for exploration or parameter tuning

•	Software architectures for effective visualization

•	Visualization and interaction user interfaces

•	Understanding and visualization of generative models

•	Visual explanation for driving policy


## Call for papers: ## 
We accept many kinds of papers, such as (and not limited to): 
Extended abstract, short papers, work-in-progress papers and demo papers. You can also submit your published work as 2-page summarization.

We encourage submissions of relevant work that has been previously published, or is to be presented at the main conference. The accepted papers will be posted on the workshop website and will not appear in the official ICML proceedings.

Submissions must be in PDF, written in English, no more than 8 pages long — shorter papers are welcome — and formatted according to the standard ICML 2017 ***[guideline]***. Submissions do not have to be anonymized.

For accepted papers, at least one author must attend the workshop to present the work.

***Submission website***: [https://cmt3.research.microsoft.com/VDL2017]





[Biye Jiang]: http://byeah.github.io
[John Canny]: http://www.eecs.berkeley.edu/~jfc/
[Polo Chau]: http://www.cc.gatech.edu/~dchau/
[Xiangmin Fan]: http://www.xiangminfan.com
[Jun-Yan Zhu]: http://people.eecs.berkeley.edu/~junyanz/
[Aditya Khosla]: https://people.csail.mit.edu/khosla/
[guideline]: https://2017.icml.cc/Conferences/2017/StyleAuthorInstructions
[https://cmt3.research.microsoft.com/VDL2017]: https://cmt3.research.microsoft.com/VDL2017
[here]: /reference
[accepted papers]: /papers	
[Jeff Clune]: http://jeffclune.com/
[Wojciech Samek]: http://iphome.hhi.de/samek/
[Yingnian Wu]: http://www.stat.ucla.edu/~ywu/
[Jason Yosinski]: http://yosinski.com/
[Junyan Zhu]: http://www.eecs.berkeley.edu/~junyanz/
[Shixia Liu]: http://shixialiu.com/
[Byron Boots]: http://www.cc.gatech.edu/~bboots3/
[Le Song]: http://www.cc.gatech.edu/~lsong/
[Deep Dream Generator]: http://deepdreamgenerator.com/
[Inceptionism]: http://googleresearch.blogspot.ch/2015/06/inceptionism-going-deeper-into-neural.html
[Martin Wattenberg]: http://www.bewitched.com/about.html
[Christopher Olah]: http://colah.github.io/about.html
[Schedule]: /schedule
[Last year]: https://icmlviz.github.io/icmlviz2016/
[ICML 2017]: https://2017.icml.cc/
[Devi Parikh]: https://filebox.ece.vt.edu/~parikh/

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-48160406-2', 'auto');
  ga('send', 'pageview');

</script>