---
layout: default
title: Home
permalink: /home/
---

# Workshop on Visualization for Deep Learning

## Organizers:

##### [Biye Jiang] (UC Berkeley, bjiang@berkeley.edu)
	
##### [John Canny] (UC Berkeley, canny@berkeley.edu)

##### [Polo Chau] (Georgia Tech, polo@gatech.edu)

##### [Aditya Khosla] (MIT, khosla@csail.mit.edu)

## Abstract##

Deep networks have had profound impact across machine learning research and in many application areas. DNNs are complex to design and train. They are non-linear systems that almost always have many local optima and are often sensitive to training parameter settings and initial state. Systematic optimization of structure and hyperparameters is possible e.g. with Bayesian optimization, but hampered by the expense of training each design on realistic datasets. Exploration is still ongoing for best design principles. We argue that visualization can play an essential role in understanding DNNs and in developing new design principles. With rich tools for visual exploration of networks during training and inference, one should be able to form closer ties between theory and practice: validating expected behaviors, and exposing the unexpected which can lead to new insights. 

## Call for papers:## 
We accept short papers, work-in-progress papers and demo papers. 
Details coming soon.

## Important Dates ##

Submission deadline: May 1, 2016

Acceptance notification:  May 10, 2016

## Topics:##
Likely topics for the workshop include, but are not limited to:

•	Directly visualizing the activations and parameters in intuitive aggregates

•	Visualizing weights as features

•	Visualizing gradient aggregates during training

•	Improving interpretability of networks:

•	Localizing "responsbility" in the network for particular outputs

•	Sensitivity/stability of network behavior

•	Visualizing loss function geometry and the trajectory of the gradient descent process

•	Visual representation of the input-output mapping of the network

•	Visualizing alternative structures and their performance

•	Monitoring/debugging the training process, i.e to detect saddle points or local optima, saturation units

•	Visualizing distributed training methods across a cluster

•	Using animation in network visualization

•	Interactive visualizations for exploration or parameter tuning

•	Software architectures for effective visualization

•	Visualization and interaction user interfaces






[Biye Jiang]: http://byeah.github.io
[John Canny]: http://www.eecs.berkeley.edu/~jfc/
[Polo Chau]: http://www.cc.gatech.edu/~dchau/
[Aditya Khosla]: https://people.csail.mit.edu/khosla/
