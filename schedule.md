---
layout: default
title: Schedule
permalink: /schedule/
order: 3
---

Location: ***C4.3 International Convention Centre***

8:30-8:45 Opening remark

8:45-9:20 Invited talk. ***Becoming friends with every pixel*** Phillip Isola (UC Berkeley)

9:20-9:40 ***[SmoothGrad: removing noise by adding noise]*** Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Viegas, Martin M Wattenberg

9:40-10:00 ***[Towards Visual Explanations for Convolutional Neural Networks via Input Resampling]*** Benjamin J Lengerich, Sandeep Konam, Eric Xing, Stephanie Rosenthal, Manuela Veloso

10:00-10:30 Coffee Breaks and Poster session

10:30-11:00 Invited talk. ***Understanding Generative Models in Google Brain Magenta*** Cinjon Resnick (Google)

11:00-11:15 ***[Deep saliency: What is learnt by a deep network about saliency?]*** Sen He, Nicolas Pugeault

11:15-11:45 Invited talk. ***Self-supervised attention for Deep Learning explanations*** Nathan Hodas, (PNL)

11:45-12:00 ***[Skip-Frame Embeddings for Feature Adaptation and Visualization]*** Zain Shah

Lunch Breaks

14:00-14:40 Invited talk. ***[Quantifying the Interpretability of Deep Visual Representations]*** Bolei Zhou (MIT)

14:40-15:00 ***[Visualizing Feature Maps in Deep Neural Networks using DeepResolve - A Genomics Case Study]*** Ge Liu, David Gifford

15:00-15:30 Coffee Breaks and Poster session

15:30-16:00 ***Visual Explanations from Deep Networks*** Dhruv Batra (Georgia Tech and Facebook AI Research)

16:00-16:20 ***[Evolutionary Visual Analysis of Deep Neural Networks]*** Wen Zhong, Cong Xie, Yuan Zhong, Yang Wang, Wei Xu, Shenghui Cheng, Klaus Mueller

16:20-16:50 Invited talk. ***[ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models]*** Pierre Andrews (Facebook)

16:50-17:30 Panel discussion. Brainstorming on deep learning visualization tools

17:30 Closing remarks


[Deep saliency: What is learnt by a deep network about saliency?]: ../assets/papers/1.pdf
[Evolutionary Visual Analysis of Deep Neural Networks]: ../assets/papers/2.pdf
[SmoothGrad: removing noise by adding noise]: ../assets/papers/3.pdf
[Towards Visual Explanations for Convolutional Neural Networks via Input Resampling]: ../assets/papers/5.pdf
[Quantifying the Interpretability of Deep Visual Representations]: ../assets/papers/6.pdf
[Visualizing Feature Maps in Deep Neural Networks using DeepResolve - A Genomics Case Study]: ../assets/papers/7.pdf
[Skip-Frame Embeddings for Feature Adaptation and Visualization]: ../assets/papers/8.pdf
[ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models]: https://arxiv.org/pdf/1704.01942.pdf




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-48160406-2', 'auto');
  ga('send', 'pageview');

</script>